<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="main.css">
    <title>CoDi</title>
</head>
<body>
<div id="title_slide">
    <div class="gradient-bg"></div>
    <div class="title_left">
        <h1>CoDi: Conditional Diffusion Distillation for <br /> Higher-Fidelity and Faster Image Generation</h1>
        <div class="author-container">
            <div class="grid-item"><a href="https://kfmei.page" style="text-decoration:underline">Kangfu Mei</a></div>
            <div class="grid-item"><a href="https://mdelbra.github.io" style="text-decoration:underline">Mauricio Delbracio</a></div>
            <div class="grid-item"><a href="https://research.google/people/hossein-talebi/" style="text-decoration:underline">Hossein Talebi</a></div>
            <div class="grid-item"><a href="https://www.linkedin.com/in/zhengzhong-tu-92419790/" style="text-decoration:underline">Zhengzhong Tu</a></div>
        </div>
        <div class="author-container">
            <div class="grid-item"><a href="https://engineering.jhu.edu/vpatel36/team/vishalpatel/" style="text-decoration:underline">Vishal M. Patel</a></div>
            <div class="grid-item"><a href="https://sites.google.com/view/milanfarhome/" style="text-decoration:underline">Peyman Milanfar</a></div>
        </div>
        <div class="berkeley"> <!-- Add UC Berkeley aligned beneath William Peebles and NYU aligned beneath Saining Xie-->
            <div class="grid-item">Google Research</div>
            <div class="grid-item">Johns Hopkins University</div>
        </div>
        <div class="button-container">
            <a href="https://arxiv.org/abs/2310.01407" class="button gradient-button">Paper</a>
            <a href="https://github.com/fast-codi/CoDi" class="button gradient-button">Code</a>
            <!-- <a href="https://huggingface.co/spaces/wpeebles/DiT" class="button gradient-button">ðŸ¤— Space</a> -->
            <!-- <a href="http://colab.research.google.com/github/facebookresearch/DiT/blob/main/run_DiT.ipynb" class="button gradient-button">Colab</a> -->
        </div>
        <figure>
            <img src="imgs/teaser-sub-a.jpg" alt="teaser" style="max-width: 100%;">
            <figcaption>
                Our proposed CoDi efficiently distills a conditional diffusion model from an unconditional one, enabling rapid generation of high-quality images under various conditional settings. We demonstrate CoDi's capabilities through generated results across various tasks.
            </figcaption>
        </figure>
        <!-- <div id="abstract" class="grid-container">
            <h1>CoDi</h1>
            <p>
                We introduce a novel method dubbed CoDi, that adapts a pre-trained latent diffusion model to accept additional image conditioning inputs while significantly reducing the sampling steps required to achieve high-quality results. Our method can leverage architectures such as ControlNet to incorporate conditioning inputs without compromising the model's prior knowledge gained during large scale pre-training. Additionally, a conditional consistency loss enforces consistent predictions across diffusion steps, effectively compelling the model to generate high-quality images with conditions in a few steps. Our conditional-task learning and distillation approach outperforms previous distillation methods, achieving a new state-of-the-art in producing high-quality images with very few steps (e.g., 1-4) across multiple tasks, including super-resolution, text-guided image editing, and depth-to-image generation.
            </p>
        </div> -->
    </div>
</div>
<hr class="rounded">
<div id="overview">
    <h1><img src="https://www.gstatic.com/android/keyboard/emojikitchen/20201001/u1f430/u1f430_u1f422.png" width=32px /> CoDi</h1>
    <p>
        We introduce a novel method dubbed CoDi, that adapts a pre-trained latent diffusion model to accept additional image conditioning inputs while significantly reducing the sampling steps required to achieve high-quality results. Our method can leverage architectures such as ControlNet to incorporate conditioning inputs without compromising the model's prior knowledge gained during large scale pre-training. Additionally, a conditional consistency loss enforces consistent predictions across diffusion steps, effectively compelling the model to generate high-quality images with conditions in a few steps. Our conditional-task learning and distillation approach outperforms previous distillation methods, achieving a new state-of-the-art in producing high-quality images with very few steps (e.g., 1-4) across multiple tasks, including super-resolution, text-guided image editing, and depth-to-image generation.
    </p>
    <figure>
        <img class="teaser-block" src="imgs/codi_animate-compress.gif" alt="The animate of codi running.">
        <figcaption class="dit-block-caption">
            <em>Screen recording of CoDi generation. CoDi completes text-guided inpainting in 4 steps, which means CoDi only needs 500~ms in TPUv5.</em>  
        </figcaption>
    </figure>

    <h1>One-stage Conditional Distillation</h1>
    <figure>
        <img class="dit-block" src="imgs/one-stage.jpg" alt="CoDi learns faster conditional sampling from unconditional pretraining.">
        <!-- <figcaption class="dit-block-caption">
        </figcaption> -->
    </figure>
    <p>
        Compared with previous (two-stage) distillation methods---either distillation-first or fine-tuning-first, CoDi is the first single-stage distillation method that directly learns faster conditional sampling from a text-to-image pretraining, yiedling a fully distilled conditional diffusion model.
    </p>

    <h1>Parameter-Efficient Conditional Distillation</h1>
    <figure>
    <img class="teaser-block" src="imgs/pe-codi.png" alt="CoDi has unique parameters-efficient distillation that only uses the half of parmaeters.">
    <!-- <figcaption class="teaser-caption">
    </figcaption> -->
    </figure>
    <p>
        CoDi offers the flexibility to selectively update parameters pertinent to distillation and conditional finetuning, leaving the remaining parameters frozen.
        This leads us to introduce a new fashion of parameter-efficient conditional distillation, aiming at unifying the distillation process across commonly-used parameter-efficient diffusion model finetuning, including ControlNet, T2I-Adapter, etc.
        Our method can then optimizes the conditional guidance and the consistency by only updating the duplicated encoder. 
    </p>

    <h1>Comparison to State-of-the-Art Diffusion Models</h1>
    <figure>
    <img class="teaser-block" src="imgs/performance.png" alt="CoDi's performance on super-resolution, inpainting, and depth-to-image benchmarks.">
    <!-- <figcaption class="teaser-caption">
    </figcaption> -->
    </figure>
    <p>
        Quantitative performance comparisons between the baselines and our methods. Our model can achieve comparable performance in 4 steps than models sampled in 250 steps. The 4-step sampling results of our parameters-efficient distillation (PE-CoDi) is comparable with the original 8-step sampling results, while PE-CoDi doesn't sacrifice the original generative performance with frozen backbone.
    </p>

    <h1>Comparison to Consistency Models</h1>
    <figure>
    <img class="teaser-block" style="max-width: 100%;" src="imgs/compare-cm.png" alt="CoDi performs better than consistency models on super-resolution and inpainting.">
    <!-- <figcaption class="teaser-caption">
    </figcaption> -->
    </figure>
    <p>
        CoDi outperforms the consistency models by generating higher quality results on the super-resolution (left) and text-guided inpainting (right) benchmarks.
    </p>


    <h1>BibTeX</h1>
    <p class="bibtex">
        @article{mei2023conditional,<br>
        &nbsp;&nbsp;title={CoDi: Conditional Diffusion Distillation for Higher-Fidelity and Faster Image Generation},<br>
        &nbsp;&nbsp;author={Mei, Kangfu and Delbracio, Mauricio and Talebi, Hossein and Tu, Zhengzhong and Patel, Vishal M and Milanfar, Peyman},<br>
        &nbsp;&nbsp;year={2023},<br>
        &nbsp;&nbsp;journal={arXiv preprint arXiv:2310.01407},<br>
        }
    </p>
</div>
</body>
</html>